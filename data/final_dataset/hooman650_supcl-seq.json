{"home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupCsTrainer.__init__": [[24, 49], ["transformers.Trainer.__init__", "print", "print"], "methods", ["home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupConLoss.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "w_drop_out", ":", "tp", ".", "Optional", "[", "tp", ".", "List", "[", "float", "]", "]", "=", "[", "0.0", ",", "0.05", ",", "0.2", "]", ",", "\n", "temperature", ":", "tp", ".", "Optional", "[", "float", "]", "=", "0.05", ",", "\n", "def_drop_out", ":", "tp", ".", "Optional", "[", "float", "]", "=", "0.1", ",", "\n", "pooling_strategy", ":", "tp", ".", "Optional", "[", "str", "]", "=", "'pooler'", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize Contrastive Learning Module and params.\n        \n        :param w_drop_out: Drop_out probabilities. THe number of views equals to the length of this list.\n        \n        :param pooling_strategy: Pooling strategy it can be either `pooler` or `mean`. \n        `pooler` employs the `[CLS]` token if available and `mean` takes the mean of the last hidden layer.\n        \n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "w_drop_out", "=", "w_drop_out", "\n", "self", ".", "temperature_s", "=", "temperature", "\n", "self", ".", "def_drop_out", "=", "def_drop_out", "\n", "self", ".", "pooling_strategy", "=", "pooling_strategy", "\n", "if", "pooling_strategy", "==", "'pooler'", ":", "\n", "            ", "print", "(", "'# Employing pooler ([CLS]) output.'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'# Employing mean of the last hidden layer.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupCsTrainer.compute_loss": [[50, 103], ["inputs.pop", "SupCsTrainer.SupCsTrainer.", "torch.normalize", "torch.normalize", "torch.normalize", "SupCsTrainer.SupConLoss", "SupConLoss.", "SupCsTrainer.SupCsTrainer.last_hidden_state.mean", "SupCsTrainer.SupCsTrainer.set_dropout_mf", "SupCsTrainer.SupCsTrainer.pooler_output.unsqueeze", "SupCsTrainer.SupCsTrainer.set_dropout_mf", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "SupCsTrainer.SupCsTrainer.last_hidden_state.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "SupCsTrainer.SupCsTrainer.last_hidden_state.mean", "SupCsTrainer.SupCsTrainer.pooler_output.unsqueeze", "SupCsTrainer.SupCsTrainer.last_hidden_state.mean", "SupCsTrainer.SupCsTrainer.", "SupCsTrainer.SupCsTrainer.", "SupCsTrainer.SupCsTrainer."], "methods", ["home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupCsTrainer.set_dropout_mf", "home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupCsTrainer.set_dropout_mf"], ["", "", "def", "compute_loss", "(", "\n", "self", ",", "\n", "model", ":", "nn", ",", "\n", "inputs", ":", "tp", ".", "Dict", ",", "\n", "return_outputs", ":", "tp", ".", "Optional", "[", "bool", "]", "=", "False", ",", "\n", ")", "->", "tp", ".", "Tuple", "[", "float", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\" Computes loss given model and its inputs.\n        \n        :param model: The model to be finetuned.   \n        \n        :param inputs: The inputs\n        \n        \"\"\"", "\n", "labels", "=", "inputs", ".", "pop", "(", "\"labels\"", ")", "\n", "\n", "# ----- Default p = 0.1 ---------#", "\n", "output", "=", "model", "(", "**", "inputs", ")", "\n", "if", "self", ".", "pooling_strategy", "==", "'pooler'", ":", "\n", "            ", "try", ":", "\n", "                ", "logits", "=", "output", ".", "pooler_output", ".", "unsqueeze", "(", "1", ")", "\n", "", "except", ":", "\n", "                ", "logits", "=", "output", ".", "last_hidden_state", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "", "", "else", ":", "\n", "            ", "logits", "=", "output", ".", "last_hidden_state", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# ---- iteratively create dropouts -----#", "\n", "", "for", "p_dpr", "in", "self", ".", "w_drop_out", ":", "\n", "# -- Set models dropout --#", "\n", "            ", "if", "p_dpr", "!=", "self", ".", "def_drop_out", ":", "\n", "                ", "model", "=", "self", ".", "set_dropout_mf", "(", "model", ",", "w", "=", "p_dpr", ")", "\n", "# ---- concat logits ------#", "\n", "", "if", "self", ".", "pooling_strategy", "==", "'pooler'", ":", "\n", "# --------- If model does offer pooler output --------#", "\n", "                ", "try", ":", "\n", "                    ", "logits", "=", "torch", ".", "cat", "(", "(", "logits", ",", "model", "(", "**", "inputs", ")", ".", "pooler_output", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", "\n", "", "except", ":", "\n", "                    ", "logits", "=", "torch", ".", "cat", "(", "(", "logits", ",", "model", "(", "**", "inputs", ")", ".", "last_hidden_state", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", ",", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "logits", "=", "torch", ".", "cat", "(", "(", "logits", ",", "model", "(", "**", "inputs", ")", ".", "last_hidden_state", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", ",", "1", ")", "\n", "\n", "# ---- L2 norm ---------#", "\n", "", "", "logits", "=", "FF", ".", "normalize", "(", "logits", ",", "p", "=", "2", ",", "dim", "=", "2", ")", "\n", "\n", "#----- Set model back to dropout = 0.1 -----#", "\n", "if", "p_dpr", "!=", "self", ".", "def_drop_out", ":", "model", "=", "self", ".", "set_dropout_mf", "(", "model", ",", "w", "=", "0.1", ")", "\n", "\n", "\n", "# SupContrast", "\n", "loss_fn", "=", "SupConLoss", "(", "temperature", "=", "self", ".", "temperature_s", ")", "# temperature=0.1", "\n", "\n", "loss", "=", "loss_fn", "(", "logits", ",", "labels", ")", "# added rounding for stsb", "\n", "\n", "return", "(", "loss", ",", "outputs", ")", "if", "return_outputs", "else", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupCsTrainer.set_dropout_mf": [[104, 126], ["hasattr"], "methods", ["None"], ["", "def", "set_dropout_mf", "(", "\n", "self", ",", "\n", "model", ":", "nn", ",", "\n", "w", ":", "tp", ".", "List", "[", "float", "]", "\n", ")", ":", "\n", "        ", "\"\"\"Alters the dropouts in the embeddings.\n        \"\"\"", "\n", "# ------ set hidden dropout -------#", "\n", "if", "hasattr", "(", "model", ",", "'module'", ")", ":", "\n", "            ", "model", ".", "module", ".", "embeddings", ".", "dropout", ".", "p", "=", "w", "\n", "for", "i", "in", "model", ".", "module", ".", "encoder", ".", "layer", ":", "\n", "                ", "i", ".", "attention", ".", "self", ".", "dropout", ".", "p", "=", "w", "\n", "i", ".", "attention", ".", "output", ".", "dropout", ".", "p", "=", "w", "\n", "i", ".", "output", ".", "dropout", ".", "p", "=", "w", "\n", "", "", "else", ":", "\n", "            ", "model", ".", "embeddings", ".", "dropout", ".", "p", "=", "w", "\n", "for", "i", "in", "model", ".", "encoder", ".", "layer", ":", "\n", "                ", "i", ".", "attention", ".", "self", ".", "dropout", ".", "p", "=", "w", "\n", "i", ".", "attention", ".", "output", ".", "dropout", ".", "p", "=", "w", "\n", "i", ".", "output", ".", "dropout", ".", "p", "=", "w", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupConLoss.__init__": [[131, 137], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupConLoss.__init__"], ["def", "__init__", "(", "self", ",", "temperature", "=", "0.07", ",", "contrast_mode", "=", "'all'", ",", "\n", "base_temperature", "=", "0.07", ")", ":", "\n", "        ", "super", "(", "SupConLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "contrast_mode", "=", "contrast_mode", "\n", "self", ".", "base_temperature", "=", "base_temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.hooman650_supcl-seq.src.SupCsTrainer.SupConLoss.forward": [[138, 215], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "mask.float().to.float().to.repeat", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "loss.view().mean.view().mean.view().mean", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "len", "ValueError", "len", "features.view.view.view", "ValueError", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "logits_max.detach", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.arange().view().to", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "mask.float().to.float().to.sum", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "ValueError", "exp_logits.sum", "loss.view().mean.view().mean.view", "labels.contiguous().view.contiguous().view.contiguous().view", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "mask.float().to.float().to.float().to", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "ValueError", "labels.contiguous().view.contiguous().view.contiguous", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "mask.float().to.float().to.float", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "labels", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Compute loss for model. If both `labels` and `mask` are None,\n        it degenerates to SimCLR unsupervised loss:\n        https://arxiv.org/pdf/2002.05709.pdf\n        Args:\n            features: hidden vector of shape [bsz, n_views, ...].\n            labels: ground truth of shape [bsz].\n            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n                has the same class as sample i. Can be asymmetric.\n        Returns:\n            A loss scalar.\n        \"\"\"", "\n", "device", "=", "(", "torch", ".", "device", "(", "'cuda'", ")", "\n", "if", "features", ".", "is_cuda", "\n", "else", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "\n", "if", "len", "(", "features", ".", "shape", ")", "<", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'`features` needs to be [bsz, n_views, ...],'", "\n", "'at least 3 dimensions are required'", ")", "\n", "", "if", "len", "(", "features", ".", "shape", ")", ">", "3", ":", "\n", "            ", "features", "=", "features", ".", "view", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "\n", "\n", "", "batch_size", "=", "features", ".", "shape", "[", "0", "]", "\n", "if", "labels", "is", "not", "None", "and", "mask", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'Cannot define both `labels` and `mask`'", ")", "\n", "", "elif", "labels", "is", "None", "and", "mask", "is", "None", ":", "\n", "            ", "mask", "=", "torch", ".", "eye", "(", "batch_size", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "labels", "is", "not", "None", ":", "\n", "            ", "labels", "=", "labels", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "if", "labels", ".", "shape", "[", "0", "]", "!=", "batch_size", ":", "\n", "                ", "raise", "ValueError", "(", "'Num of labels does not match num of features'", ")", "\n", "", "mask", "=", "torch", ".", "eq", "(", "labels", ",", "labels", ".", "T", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "mask", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "contrast_count", "=", "features", ".", "shape", "[", "1", "]", "\n", "contrast_feature", "=", "torch", ".", "cat", "(", "torch", ".", "unbind", "(", "features", ",", "dim", "=", "1", ")", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "contrast_mode", "==", "'one'", ":", "\n", "            ", "anchor_feature", "=", "features", "[", ":", ",", "0", "]", "\n", "anchor_count", "=", "1", "\n", "", "elif", "self", ".", "contrast_mode", "==", "'all'", ":", "\n", "            ", "anchor_feature", "=", "contrast_feature", "\n", "anchor_count", "=", "contrast_count", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown mode: {}'", ".", "format", "(", "self", ".", "contrast_mode", ")", ")", "\n", "\n", "# compute logits", "\n", "", "anchor_dot_contrast", "=", "torch", ".", "div", "(", "\n", "torch", ".", "matmul", "(", "anchor_feature", ",", "contrast_feature", ".", "T", ")", ",", "\n", "self", ".", "temperature", ")", "\n", "# for numerical stability", "\n", "logits_max", ",", "_", "=", "torch", ".", "max", "(", "anchor_dot_contrast", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "logits", "=", "anchor_dot_contrast", "-", "logits_max", ".", "detach", "(", ")", "\n", "\n", "# tile mask", "\n", "mask", "=", "mask", ".", "repeat", "(", "anchor_count", ",", "contrast_count", ")", "\n", "# mask-out self-contrast cases", "\n", "logits_mask", "=", "torch", ".", "scatter", "(", "\n", "torch", ".", "ones_like", "(", "mask", ")", ",", "\n", "1", ",", "\n", "torch", ".", "arange", "(", "batch_size", "*", "anchor_count", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "to", "(", "device", ")", ",", "\n", "0", "\n", ")", "\n", "mask", "=", "mask", "*", "logits_mask", "\n", "\n", "# compute log_prob", "\n", "exp_logits", "=", "torch", ".", "exp", "(", "logits", ")", "*", "logits_mask", "\n", "log_prob", "=", "logits", "-", "torch", ".", "log", "(", "exp_logits", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n", "# compute mean of log-likelihood over positive", "\n", "mean_log_prob_pos", "=", "(", "mask", "*", "log_prob", ")", ".", "sum", "(", "1", ")", "/", "mask", ".", "sum", "(", "1", ")", "\n", "\n", "# loss", "\n", "loss", "=", "-", "(", "self", ".", "temperature", "/", "self", ".", "base_temperature", ")", "*", "mean_log_prob_pos", "\n", "loss", "=", "loss", ".", "view", "(", "anchor_count", ",", "batch_size", ")", ".", "mean", "(", ")", "\n", "\n", "return", "loss", "", "", "", ""]]}